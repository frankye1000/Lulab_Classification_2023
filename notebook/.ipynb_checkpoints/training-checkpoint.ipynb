{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, Sequential\n",
    "from tensorflow.keras.layers import Dropout, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras.metrics import Balanceacc\n",
    "\n",
    "from models import efficientNetV2B0_model, efficientNetV2B3_model\n",
    "from config import efficientNet_config\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import os\n",
    "# 使用第一張 GPU 卡\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "height  = efficientNet_config['height_B0']\n",
    "width   = efficientNet_config['width_B0']\n",
    "input_shape  = efficientNet_config['input_shape_B0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 讀取資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir      = '../dataset_22video_20221031/train'\n",
    "validation_dir = '../dataset_22video_20221031/validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_arrays = []\n",
    "train_img_labels = []\n",
    "validation_img_arrays = []\n",
    "validation_img_labels = []\n",
    "\n",
    "## train\n",
    "img_paths = glob(train_dir + \"/0/*.png\")\n",
    "for img_path in img_paths:\n",
    "    # imege\n",
    "    img_array = cv.imread(img_path)\n",
    "    img_array = cv.resize(img_array,(height,width))     # resize to (224,224)\n",
    "    train_img_arrays.append(img_array)\n",
    "    #label\n",
    "    train_img_labels.append([0])\n",
    "\n",
    "img_paths = glob(train_dir + \"/1/*.png\")\n",
    "for img_path in img_paths:\n",
    "    # imege\n",
    "    img_array = cv.imread(img_path)\n",
    "    img_array = cv.resize(img_array,(height,width))      # resize to (224,224)\n",
    "    train_img_arrays.append(img_array)\n",
    "    #label\n",
    "    train_img_labels.append([1])\n",
    "\n",
    "\n",
    "## validation\n",
    "img_paths = glob(validation_dir + \"/0/*.png\")\n",
    "for img_path in img_paths:\n",
    "    # imege\n",
    "    img_array = cv.imread(img_path)\n",
    "    img_array = cv.resize(img_array,(height,width))      # resize to (224,224)\n",
    "    validation_img_arrays.append(img_array)\n",
    "    #label\n",
    "    validation_img_labels.append([0])\n",
    "\n",
    "img_paths = glob(validation_dir + \"/1/*.png\")\n",
    "for img_path in img_paths:\n",
    "    # imege\n",
    "    img_array = cv.imread(img_path)\n",
    "    img_array = cv.resize(img_array,(height,width))      # resize to (224,224)\n",
    "    validation_img_arrays.append(img_array)\n",
    "    #label\n",
    "    validation_img_labels.append([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集數量=  727\n"
     ]
    }
   ],
   "source": [
    "print('訓練集數量= ', len(train_img_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "驗證集數量=  379\n"
     ]
    }
   ],
   "source": [
    "print('驗證集數量= ',len(validation_img_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_arrays = np.array(train_img_arrays)\n",
    "train_img_labels = np.array(train_img_labels)\n",
    "validation_img_arrays = np.array(validation_img_arrays)\n",
    "validation_img_labels = np.array(validation_img_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_arrays, train_img_labels = shuffle(train_img_arrays,train_img_labels)\n",
    "validation_img_arrays, validation_img_labels = shuffle(validation_img_arrays,validation_img_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集維度=  (727, 224, 224, 3)\n",
      "測試集維度=  (379, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print('訓練集維度= ',train_img_arrays.shape)\n",
    "print('測試集維度= ',validation_img_arrays.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 14:02:28.463498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-13 14:02:28.471765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-13 14:02:28.472635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-13 14:02:28.474186: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-13 14:02:28.474929: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-13 14:02:28.475653: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-13 14:02:28.476346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-13 14:02:28.865655: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-13 14:02:28.866132: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-13 14:02:28.866568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-13 14:02:28.866940: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10113 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n",
      "24274472/24274472 [==============================] - 0s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetv2-b0 (Function  (None, 1280)             5919312   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,920,593\n",
      "Trainable params: 5,859,985\n",
      "Non-trainable params: 60,608\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = efficientNetV2B0_model()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(learning_rate=1e-4),\n",
    "              metrics=['accuracy', \n",
    "#                         Balanceacc()\n",
    "                      ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = '20230213'\n",
    "checkpoint_filepath = '../model/202211/{}.weights'.format(day)\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_acc',\n",
    "        mode='max',\n",
    "        save_best_only=True)\n",
    "\n",
    "# learning rate 降低\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "#                               factor=0.1,\n",
    "#                               patience=5, \n",
    "#                               min_lr=1e-6)\n",
    "\n",
    "\n",
    "\n",
    "callbacks = [model_checkpoint_callback, \n",
    "             #reduce_lr\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 14:03:07.766384: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - ETA: 0s - loss: 0.5185 - accuracy: 0.7565WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "23/23 [==============================] - 11s 186ms/step - loss: 0.5185 - accuracy: 0.7565 - val_loss: 0.2730 - val_accuracy: 0.9340\n",
      "Epoch 2/1000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2361 - accuracy: 0.9298WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "23/23 [==============================] - 3s 119ms/step - loss: 0.2361 - accuracy: 0.9298 - val_loss: 0.1554 - val_accuracy: 0.9472\n",
      "Epoch 3/1000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1318 - accuracy: 0.9601WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "23/23 [==============================] - 3s 119ms/step - loss: 0.1318 - accuracy: 0.9601 - val_loss: 0.1285 - val_accuracy: 0.9472\n",
      "Epoch 4/1000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0668 - accuracy: 0.9945WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "23/23 [==============================] - 3s 119ms/step - loss: 0.0668 - accuracy: 0.9945 - val_loss: 0.1169 - val_accuracy: 0.9578\n",
      "Epoch 5/1000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0480 - accuracy: 0.9890WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "23/23 [==============================] - 3s 120ms/step - loss: 0.0480 - accuracy: 0.9890 - val_loss: 0.1189 - val_accuracy: 0.9710\n",
      "Epoch 6/1000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0283 - accuracy: 0.9917WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "23/23 [==============================] - 3s 121ms/step - loss: 0.0283 - accuracy: 0.9917 - val_loss: 0.1241 - val_accuracy: 0.9657\n",
      "Epoch 7/1000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "23/23 [==============================] - 3s 122ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9578\n",
      "Epoch 8/1000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9986WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "23/23 [==============================] - 3s 124ms/step - loss: 0.0168 - accuracy: 0.9986 - val_loss: 0.1184 - val_accuracy: 0.9551\n",
      "Epoch 9/1000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0111 - accuracy: 0.9972WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "23/23 [==============================] - 3s 122ms/step - loss: 0.0111 - accuracy: 0.9972 - val_loss: 0.1289 - val_accuracy: 0.9578\n",
      "Epoch 10/1000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 0.9986WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "23/23 [==============================] - 3s 120ms/step - loss: 0.0113 - accuracy: 0.9986 - val_loss: 0.1407 - val_accuracy: 0.9499\n",
      "Epoch 11/1000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "23/23 [==============================] - 3s 121ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.9499\n",
      "Epoch 12/1000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0089 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "23/23 [==============================] - 3s 120ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.1412 - val_accuracy: 0.9551\n",
      "Epoch 13/1000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0041 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "23/23 [==============================] - 3s 121ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1301 - val_accuracy: 0.9657\n",
      "Epoch 14/1000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "23/23 [==============================] - 3s 122ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9578\n",
      "Epoch 15/1000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "23/23 [==============================] - 3s 124ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1351 - val_accuracy: 0.9604\n",
      "Epoch 16/1000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0024 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "23/23 [==============================] - 3s 121ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1305 - val_accuracy: 0.9604\n",
      "Epoch 17/1000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "23/23 [==============================] - 3s 120ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.9551\n",
      "Epoch 18/1000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "23/23 [==============================] - 3s 121ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1310 - val_accuracy: 0.9578\n",
      "Epoch 19/1000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "23/23 [==============================] - 3s 121ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1637 - val_accuracy: 0.9578\n",
      "Epoch 20/1000\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9986WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "23/23 [==============================] - 3s 120ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.1511 - val_accuracy: 0.9525\n",
      "Epoch 21/1000\n",
      "12/23 [==============>...............] - ETA: 1s - loss: 0.0043 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14313/3430603614.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 訓練\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      4\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_img_arrays\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_img_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 訓練\n",
    "epochs = 1000\n",
    "history = model.fit(\n",
    "      x = train_img_arrays,\n",
    "      y = train_img_labels,\n",
    "      validation_data = (validation_img_arrays,validation_img_labels),      \n",
    "      epochs          = epochs,\n",
    "      verbose         = 1,\n",
    "      callbacks       = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 畫圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss         = history.history['loss']\n",
    "val_loss     = history.history['val_loss']\n",
    "accuracy     = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "BlA          = history.history['balanceacc']\n",
    "val_BlA      = history.history['val_balanceacc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(1, epochs+1)]\n",
    "\n",
    "min_valloss_x = val_loss.index(min(val_loss)) + 1\n",
    "min_valloss_y = min(val_loss)\n",
    "\n",
    "plt.figure(figsize=(24,4))\n",
    "plt.plot(x, loss, 'r')     \n",
    "plt.plot(x, val_loss, 'b')     # red dotted line (no marker)\n",
    "\n",
    "plt.plot(min_valloss_x, min_valloss_y, 'd', color='g')\n",
    "plt.text(min_valloss_x, min_valloss_y, \"({},{})\".format(min_valloss_x,round(min_valloss_y,2)), ha='left',va='top',fontsize=20)\n",
    "\n",
    "plt.legend(['loss','val_loss'])\n",
    "plt.ylim((0, 1.0))\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('loss')\n",
    "plt.savefig('../model/202211/{}_loss.png'.format(day),\n",
    "            bbox_inches='tight',\n",
    "            pad_inches=1,\n",
    "            transparent=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(1, epochs+1)]\n",
    "\n",
    "max_valacc_x = val_accuracy.index(max(val_accuracy)) + 1\n",
    "max_valacc_y = max(val_accuracy)\n",
    "\n",
    "plt.figure(figsize=(24,4))\n",
    "plt.plot(x, accuracy, 'r')     \n",
    "plt.plot(x, val_accuracy, 'b')     # red dotted line (no marker)\n",
    "\n",
    "plt.plot(max_valacc_x, max_valacc_y, 'd', color='g')\n",
    "plt.text(max_valacc_x, max_valacc_y, \"({},{})\".format(max_valacc_x, round(max_valacc_y,2)), ha='left',va='top',fontsize=20)\n",
    "\n",
    "plt.legend(['accuracy','val_accuracy'])\n",
    "plt.ylim((0, 1.1))\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('accuracy')\n",
    "plt.savefig('../model/202211/{}_acc.png'.format(day),\n",
    "            bbox_inches='tight',\n",
    "            pad_inches=1,\n",
    "            transparent=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(1, epochs+1)]\n",
    "\n",
    "max_valBlA_x = val_BlA.index(max(val_BlA)) + 1\n",
    "max_valBlA_y = max(val_BlA)\n",
    "\n",
    "plt.figure(figsize=(24,4))\n",
    "plt.plot(x, BlA, 'r')     \n",
    "plt.plot(x, val_BlA, 'b')     # red dotted line (no marker)\n",
    "\n",
    "plt.plot(max_valBlA_x, max_valBlA_y, 'd', color='g')\n",
    "plt.text(max_valBlA_x, max_valBlA_y, \"({},{})\".format(max_valBlA_x, round(max_valBlA_y,2)), ha='left',va='top',fontsize=20)\n",
    "\n",
    "plt.legend(['balance accuracy','val_balance accuracy'])\n",
    "plt.ylim((0, 1.1))\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('balance accuracy')\n",
    "plt.title('balance accuracy')\n",
    "plt.savefig('../model/202211/{}_BlA.png'.format(day),\n",
    "            bbox_inches='tight',\n",
    "            pad_inches=1,\n",
    "            transparent=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Get the dictionary containing each metric and the loss for each epoch\n",
    "history_dict = history.history\n",
    "# Save it under the form of a json file\n",
    "json.dump(history_dict, open('../model/202211/{}.history'.format(day), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e60de47cb3857121f9ee587fa65ec3e886692403f703077c3e6fd7aef069122f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
