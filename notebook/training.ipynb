{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, Sequential\n",
    "from tensorflow.keras.layers import Dropout, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.metrics import Balanceacc\n",
    "\n",
    "from models import efficientNetV2B0_model, efficientNetV2B3_model\n",
    "from config import efficientNet_config\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import os\n",
    "# 使用第一張 GPU 卡\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height  = efficientNet_config['height_B0']\n",
    "width   = efficientNet_config['width_B0']\n",
    "input_shape  = efficientNet_config['input_shape_B0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 讀取資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir      = '../dataset_22video_20221031/train'\n",
    "validation_dir = '../dataset_22video_20221031/validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_arrays = []\n",
    "train_img_labels = []\n",
    "validation_img_arrays = []\n",
    "validation_img_labels = []\n",
    "\n",
    "## train\n",
    "img_paths = glob(train_dir + \"/0/*.png\")\n",
    "for img_path in img_paths:\n",
    "    # imege\n",
    "    img_array = cv.imread(img_path)\n",
    "    img_array = cv.resize(img_array,(height,width))     # resize to (224,224)\n",
    "    train_img_arrays.append(img_array)\n",
    "    #label\n",
    "    train_img_labels.append([0])\n",
    "\n",
    "img_paths = glob(train_dir + \"/1/*.png\")\n",
    "for img_path in img_paths:\n",
    "    # imege\n",
    "    img_array = cv.imread(img_path)\n",
    "    img_array = cv.resize(img_array,(height,width))      # resize to (224,224)\n",
    "    train_img_arrays.append(img_array)\n",
    "    #label\n",
    "    train_img_labels.append([1])\n",
    "\n",
    "\n",
    "## validation\n",
    "img_paths = glob(validation_dir + \"/0/*.png\")\n",
    "for img_path in img_paths:\n",
    "    # imege\n",
    "    img_array = cv.imread(img_path)\n",
    "    img_array = cv.resize(img_array,(height,width))      # resize to (224,224)\n",
    "    validation_img_arrays.append(img_array)\n",
    "    #label\n",
    "    validation_img_labels.append([0])\n",
    "\n",
    "img_paths = glob(validation_dir + \"/1/*.png\")\n",
    "for img_path in img_paths:\n",
    "    # imege\n",
    "    img_array = cv.imread(img_path)\n",
    "    img_array = cv.resize(img_array,(height,width))      # resize to (224,224)\n",
    "    validation_img_arrays.append(img_array)\n",
    "    #label\n",
    "    validation_img_labels.append([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('訓練集數量= ', len(train_img_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('驗證集數量= ',len(validation_img_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_arrays = np.array(train_img_arrays)\n",
    "train_img_labels = np.array(train_img_labels)\n",
    "validation_img_arrays = np.array(validation_img_arrays)\n",
    "validation_img_labels = np.array(validation_img_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_arrays, train_img_labels = shuffle(train_img_arrays,train_img_labels)\n",
    "validation_img_arrays, validation_img_labels = shuffle(validation_img_arrays,validation_img_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('訓練集維度= ',train_img_arrays.shape)\n",
    "print('測試集維度= ',validation_img_arrays.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = efficientNetV2B0_model()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(learning_rate=1e-4),\n",
    "              metrics=['accuracy', \n",
    "                        Balanceacc()\n",
    "                      ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = '20230213'\n",
    "checkpoint_filepath = '../model/202211/{}.weights'.format(day)\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=True,\n",
    "        monitor='val_balanceacc',\n",
    "        mode='max',\n",
    "        save_best_only=True)\n",
    "\n",
    "# learning rate 降低\n",
    "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
    "#                               factor=0.1,\n",
    "#                               patience=5, \n",
    "#                               min_lr=1e-6)\n",
    "\n",
    "\n",
    "\n",
    "callbacks = [model_checkpoint_callback, \n",
    "             #reduce_lr\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練\n",
    "epochs = 1000\n",
    "history = model.fit(\n",
    "      x = train_img_arrays,\n",
    "      y = train_img_labels,\n",
    "      validation_data = (validation_img_arrays,validation_img_labels),      \n",
    "      epochs          = epochs,\n",
    "      verbose         = 1,\n",
    "      callbacks       = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 畫圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss         = history.history['loss']\n",
    "val_loss     = history.history['val_loss']\n",
    "accuracy     = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "BlA          = history.history['balanceacc']\n",
    "val_BlA      = history.history['val_balanceacc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(1, epochs+1)]\n",
    "\n",
    "min_valloss_x = val_loss.index(min(val_loss)) + 1\n",
    "min_valloss_y = min(val_loss)\n",
    "\n",
    "plt.figure(figsize=(24,4))\n",
    "plt.plot(x, loss, 'r')     \n",
    "plt.plot(x, val_loss, 'b')     # red dotted line (no marker)\n",
    "\n",
    "plt.plot(min_valloss_x, min_valloss_y, 'd', color='g')\n",
    "plt.text(min_valloss_x, min_valloss_y, \"({},{})\".format(min_valloss_x,round(min_valloss_y,2)), ha='left',va='top',fontsize=20)\n",
    "\n",
    "plt.legend(['loss','val_loss'])\n",
    "plt.ylim((0, 1.0))\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('loss')\n",
    "plt.savefig('../model/202211/{}_loss.png'.format(day),\n",
    "            bbox_inches='tight',\n",
    "            pad_inches=1,\n",
    "            transparent=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(1, epochs+1)]\n",
    "\n",
    "max_valacc_x = val_accuracy.index(max(val_accuracy)) + 1\n",
    "max_valacc_y = max(val_accuracy)\n",
    "\n",
    "plt.figure(figsize=(24,4))\n",
    "plt.plot(x, accuracy, 'r')     \n",
    "plt.plot(x, val_accuracy, 'b')     # red dotted line (no marker)\n",
    "\n",
    "plt.plot(max_valacc_x, max_valacc_y, 'd', color='g')\n",
    "plt.text(max_valacc_x, max_valacc_y, \"({},{})\".format(max_valacc_x, round(max_valacc_y,2)), ha='left',va='top',fontsize=20)\n",
    "\n",
    "plt.legend(['accuracy','val_accuracy'])\n",
    "plt.ylim((0, 1.1))\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('accuracy')\n",
    "plt.savefig('../model/202211/{}_acc.png'.format(day),\n",
    "            bbox_inches='tight',\n",
    "            pad_inches=1,\n",
    "            transparent=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(1, epochs+1)]\n",
    "\n",
    "max_valBlA_x = val_BlA.index(max(val_BlA)) + 1\n",
    "max_valBlA_y = max(val_BlA)\n",
    "\n",
    "plt.figure(figsize=(24,4))\n",
    "plt.plot(x, BlA, 'r')     \n",
    "plt.plot(x, val_BlA, 'b')     # red dotted line (no marker)\n",
    "\n",
    "plt.plot(max_valBlA_x, max_valBlA_y, 'd', color='g')\n",
    "plt.text(max_valBlA_x, max_valBlA_y, \"({},{})\".format(max_valBlA_x, round(max_valBlA_y,2)), ha='left',va='top',fontsize=20)\n",
    "\n",
    "plt.legend(['balance accuracy','val_balance accuracy'])\n",
    "plt.ylim((0, 1.1))\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('balance accuracy')\n",
    "plt.title('balance accuracy')\n",
    "plt.savefig('../model/202211/{}_BlA.png'.format(day),\n",
    "            bbox_inches='tight',\n",
    "            pad_inches=1,\n",
    "            transparent=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Get the dictionary containing each metric and the loss for each epoch\n",
    "history_dict = history.history\n",
    "# Save it under the form of a json file\n",
    "json.dump(history_dict, open('../model/202211/{}.history'.format(day), 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "1448b48b023bcc9c3d4a79e814720a10ca6d4244f75e0f7ce4af58f96ba2b7d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
