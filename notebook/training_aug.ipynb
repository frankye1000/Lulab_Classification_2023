{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import models, Sequential\n",
    "from tensorflow.keras.layers import Dropout, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from models import efficientNetV2B0_model, efficientNetV2B3_model\n",
    "from config import efficientNet_config\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "height  = efficientNet_config['height_B0']\n",
    "width   = efficientNet_config['width_B0']\n",
    "input_shape  = efficientNet_config['input_shape_B0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 讀取資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir      = '../dataset_smooth_22video_20221031/train'\n",
    "validation_dir = '../dataset_smooth_22video_20221031/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_arrays = []\n",
    "train_img_labels = []\n",
    "validation_img_arrays = []\n",
    "validation_img_labels = []\n",
    "\n",
    "## train\n",
    "img_paths = glob(train_dir + \"/0/*.png\")\n",
    "for img_path in img_paths:\n",
    "    # imege\n",
    "    img_array = cv.imread(img_path)\n",
    "    img_array = cv.resize(img_array,(height,width))     # resize to (224,224)\n",
    "    train_img_arrays.append(img_array)\n",
    "    #label\n",
    "    train_img_labels.append([0])\n",
    "\n",
    "img_paths = glob(train_dir + \"/1/*.png\")\n",
    "for img_path in img_paths:\n",
    "    # imege\n",
    "    img_array = cv.imread(img_path)\n",
    "    img_array = cv.resize(img_array,(height,width))      # resize to (224,224)\n",
    "    train_img_arrays.append(img_array)\n",
    "    #label\n",
    "    train_img_labels.append([1])\n",
    "\n",
    "\n",
    "## validation\n",
    "img_paths = glob(validation_dir + \"/0/*.png\")\n",
    "for img_path in img_paths:\n",
    "    # imege\n",
    "    img_array = cv.imread(img_path)\n",
    "    img_array = cv.resize(img_array,(height,width))      # resize to (224,224)\n",
    "    validation_img_arrays.append(img_array)\n",
    "    #label\n",
    "    validation_img_labels.append([0])\n",
    "\n",
    "img_paths = glob(validation_dir + \"/1/*.png\")\n",
    "for img_path in img_paths:\n",
    "    # imege\n",
    "    img_array = cv.imread(img_path)\n",
    "    img_array = cv.resize(img_array,(height,width))      # resize to (224,224)\n",
    "    validation_img_arrays.append(img_array)\n",
    "    #label\n",
    "    validation_img_labels.append([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集數量=  723\n"
     ]
    }
   ],
   "source": [
    "print('訓練集數量= ', len(train_img_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "驗證集數量=  379\n"
     ]
    }
   ],
   "source": [
    "print('驗證集數量= ',len(validation_img_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_arrays = np.array(train_img_arrays)\n",
    "train_img_labels = np.array(train_img_labels)\n",
    "validation_img_arrays = np.array(validation_img_arrays)\n",
    "validation_img_labels = np.array(validation_img_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集維度=  (723, 224, 224, 3)\n",
      "驗證集維度=  (379, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print('訓練集維度= ',train_img_arrays.shape)\n",
    "print('驗證集維度= ',validation_img_arrays.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 資料擴增"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''https://medium.com/ai%E5%8F%8D%E6%96%97%E5%9F%8E/preprocessing-data-image-data-augmentation%E5%AF%A6%E4%BD%9C%E8%88%87%E5%8F%83%E6%95%B8%E8%AA%AA%E6%98%8E-d05f2ed24194'''\n",
    "\n",
    "datagen = ImageDataGenerator(  \n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-6,\n",
    "    # rotation_range=180.,\n",
    "    # width_shift_range=0.,\n",
    "    # height_shift_range=0.,\n",
    "    # shear_range=0.,\n",
    "    zoom_range=0.,\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    # cval=0.,\n",
    "    rescale=None,\n",
    "    # preprocessing_function=None\n",
    "    )\n",
    "# rescale=1./255,\n",
    "# rotation_range=0,\n",
    "# width_shift_range=0.2,\n",
    "# height_shift_range=0.2,\n",
    "# shear_range=0.2,\n",
    "# zoom_range=0.2,\n",
    "# horizontal_flip=True,\n",
    "# fill_mode='nearest',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = efficientNetV2B0_model()\n",
    "\n",
    "# TODO: 嘗試看看新的\n",
    "# https://stackoverflow.com/questions/71909901/guiding-tensorflow-keras-model-training-to-achieve-best-recall-at-precision-0-95\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(learning_rate=1e-4),\n",
    "              metrics=['accuracy',\n",
    "                       tf.keras.metrics.Recall(name='recall', thresholds=0.5)\n",
    "                      ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = '20220917'\n",
    "checkpoint_filepath = '../model/202209/{}.weights'.format(day)\n",
    "# model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "#                                                                monitor='val_accuracy',\n",
    "#                                                                mode='max',\n",
    "#                                                                save_weights_only=True,\n",
    "#                                                                save_best_only=True)\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                                                               monitor='val_recall',\n",
    "                                                               mode='max',\n",
    "                                                               save_freq='epoch',\n",
    "                                                               save_weights_only=True,\n",
    "                                                               save_best_only=True,\n",
    "                                                               verbose=1)\n",
    "\n",
    "callbacks = [model_checkpoint_callback,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用第二張 GPU 卡\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "# 訓練\n",
    "epochs = 1000\n",
    "history = model.fit(\n",
    "      datagen.flow(train_img_arrays, train_img_labels, batch_size=32),\n",
    "      validation_data = (validation_img_arrays,validation_img_labels),      \n",
    "      epochs          = epochs,\n",
    "      callbacks       = callbacks,\n",
    "      verbose         = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 畫圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss         = history.history['loss']\n",
    "val_loss     = history.history['val_loss']\n",
    "accuracy     = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "recall       = history.history['recall']\n",
    "val_recall   = history.history['val_recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(1, epochs+1)]\n",
    "\n",
    "max_valrecall_x = val_recall.index(max(val_recall)) + 1\n",
    "max_valrecall_y = max(val_recall)\n",
    "\n",
    "plt.figure(figsize=(24,4))\n",
    "plt.plot(x, recall, 'r')     \n",
    "plt.plot(x, val_recall, 'b')     # red dotted line (no marker)\n",
    "\n",
    "plt.plot(max_valrecall_x, max_valrecall_y, 'd', color='g')\n",
    "plt.text(max_valrecall_x, max_valrecall_y, \"({},{})\".format(max_valrecall_x,round(max_valrecall_y,2)), ha='left',va='top',fontsize=20)\n",
    "\n",
    "plt.legend(['recall','val_recall'])\n",
    "plt.ylim((0, 1.0))\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('recall')\n",
    "plt.title('recall')\n",
    "plt.savefig('../model/202209/{}_recall.png'.format(day))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(1, epochs+1)]\n",
    "\n",
    "max_valacc_x = val_accuracy.index(max(val_accuracy)) + 1\n",
    "max_valacc_y = max(val_accuracy)\n",
    "\n",
    "plt.figure(figsize=(24,4))\n",
    "plt.plot(x, accuracy, 'r')     \n",
    "plt.plot(x, val_accuracy, 'b')     # red dotted line (no marker)\n",
    "\n",
    "plt.plot(max_valacc_x, max_valacc_y, 'd', color='g')\n",
    "plt.text(max_valacc_x, max_valacc_y, \"({},{})\".format(max_valacc_x, round(max_valacc_y,2)), ha='left',va='top',fontsize=20)\n",
    "\n",
    "plt.legend(['accuracy','val_accuracy'])\n",
    "plt.ylim((0, 1.1))\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('accuracy')\n",
    "plt.savefig('../model/202209/{}_acc.png'.format(day))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i for i in range(1, epochs+1)]\n",
    "\n",
    "min_valloss_x = val_loss.index(min(val_loss)) + 1\n",
    "min_valloss_y = min(val_loss)\n",
    "\n",
    "plt.figure(figsize=(24,4))\n",
    "plt.plot(x, loss, 'r')     \n",
    "plt.plot(x, val_loss, 'b')     # red dotted line (no marker)\n",
    "\n",
    "plt.plot(min_valloss_x, min_valloss_y, 'd', color='g')\n",
    "plt.text(min_valloss_x, min_valloss_y, \"({},{})\".format(min_valloss_x,round(min_valloss_y,2)), ha='left',va='top',fontsize=20)\n",
    "\n",
    "plt.legend(['loss','val_loss'])\n",
    "plt.ylim((0, 1.0))\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('loss')\n",
    "plt.savefig('../model/202209/{}_loss.png'.format(day))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../model/202209/{}.history'.format(day),'wb') as f:\n",
    "    pickle.dump(history, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1448b48b023bcc9c3d4a79e814720a10ca6d4244f75e0f7ce4af58f96ba2b7d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
